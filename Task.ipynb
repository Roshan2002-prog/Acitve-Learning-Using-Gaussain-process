{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8559a354",
   "metadata": {},
   "source": [
    "## Active Learning Task for Engine example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6747d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages from requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "# Be sure that you have the required version of sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2976c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e53ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the first part of the ground truth model\n",
    "rf = joblib.load('ground_truth.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to generate noise on the data and scale the output of the ground truth model accordingly\n",
    "def give_noise(y_test, noise):\n",
    "    y_test[:, 0] = np.exp(y_test[:, 0] * (1 + np.log(1.03) * noise[:, 0]))\n",
    "    y_test[:, 1] = np.exp(y_test[:, 1] * (1 + np.log(1.1) * noise[:, 1]))\n",
    "    y_test[:, 2] = (1 + 0.02 * noise[:, 2] ) * y_test[:, 2]\n",
    "    y_test[:, 3] = np.exp(y_test[:, 3] * (1 + np.log(1.1) * noise[:, 3]))\n",
    "    y_test[:, 4] = (1 + 0.02 * noise[:, 4]) * y_test[:, 4]\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e40565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full ground truth model\n",
    "def ground_truth(x, rf, noise):\n",
    "    y_test = rf.predict(x)\n",
    "    y_test = give_noise(y_test, noise)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the given data\n",
    "train_input = np.load('train_input.npy')\n",
    "train_output = np.load('train_output.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48d951",
   "metadata": {},
   "source": [
    "### Constraints for the input parameters\n",
    "Engine speed: $[1000, 2000]$\n",
    "\n",
    "Engine load: $[0, 100]$\n",
    "\n",
    "Railpressure: $[1000, 2000]$\n",
    "\n",
    "Air supply: $[200, 700]$\n",
    "\n",
    "Crank angle: $[-4, 6]$\n",
    "\n",
    "Intake pressure: $[1500, 3000]$\n",
    "\n",
    "Back pressure: $[1500, 3500]$\n",
    "\n",
    "Intake temperature: $[40, 70]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounds for the input parameters\n",
    "# The bounds are defined as a 2D array where each row corresponds to a parameter and\n",
    "# the two columns represent the lower and upper bounds respectively.\n",
    "bounds = np.array([[1000., 2000.], [0., 100.], [1000., 2000.], [200., 700.],\n",
    "                   [-4., 6.], [1500., 3000.], [1500., 3500.], [40., 70.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7794f87",
   "metadata": {},
   "source": [
    "1. Generate a probabilistic model out of the 25 given data points. \n",
    "\n",
    "2. Now iteratively add the data point with the highest predictive variance to the model for 175 rounds.\n",
    "\n",
    "3. Plot the model quality over the amount of data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
